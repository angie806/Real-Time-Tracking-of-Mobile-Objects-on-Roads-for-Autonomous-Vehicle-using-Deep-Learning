{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cd9fd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUse this ipynb to run inference for the following TensorFlow models:\\n- CenterNet HourGlass104 512x512\\n- SSD MobileNet V2 FPNLite 320, adapted to 640\\n\\nFor this code to run, a specific folder structure is required;\\ndifferent folder structure can be used after specifying the paths for all required files.\\n\\nModel training is not covered in this notebook. \\n\\nSoftware requirements are only covered briefly here. It is highly recommended to use a separate environemnt,\\nsuch as Conda environment or Docker container.\\nSome software requirements:\\n- TensorFlow Object Detection API\\n- Protobuf for TF OD API\\n- Any necessary Python packages and Path/Env variables required by the above\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use this ipynb to run inference for the following TensorFlow models:\n",
    "- CenterNet HourGlass104 512x512\n",
    "- SSD MobileNet V2 FPNLite 320, adapted to 640\n",
    "\n",
    "For this code to run, a specific folder structure is required;\n",
    "different folder structure can be used after specifying the paths for all required files.\n",
    "Default folder structure:\n",
    "main folder\n",
    "  - Tensorflow\n",
    "    - models\n",
    "    - protoc\n",
    "    - scripts\n",
    "    - workspace\n",
    "      - annotations\n",
    "      - images\n",
    "      - models\n",
    "      - pre-trained-models\n",
    "\n",
    "Model training is not covered in this notebook. \n",
    "\n",
    "Software requirements are only covered briefly here. It is highly recommended to use a separate environemnt,\n",
    "such as Conda environment or Docker container.\n",
    "Some software requirements:\n",
    "- TensorFlow Object Detection API\n",
    "- Protobuf for TF OD API\n",
    "- Any necessary Python packages and Path/Env variables required by the above\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5d3d6",
   "metadata": {},
   "source": [
    "### Folder Structure and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cfcd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e790f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model file name and TF2 model zoo url\n",
    "CUSTOM_MODEL_NAME = 'CenterNet' \n",
    "PRETRAINED_MODEL_NAME = 'centernet_hg104_512x512_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200713/centernet_hg104_512x512_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "# Label map and TF record no need to change, because we are using the same dataset as SSD model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c2a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d977bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd321c1",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6edd45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "from xml.dom.minidom import parseString\n",
    "from lxml.etree import Element, SubElement, tostring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "One cell to automate reading images, run inference, and write predictions to xml file.\n",
    "Remember to change input images dir, confidence threshold, SSD model checkpoint at the top;\n",
    "and where to save prediction xml files in the xml block towards the end of this cell.\n",
    "\"\"\"\n",
    "\n",
    "# Images folder/path\n",
    "# IMAGE_PATH = r'D:\\DL_data\\Accuracy\\Images'    # CHANGE this, it's where you store images to be fed to the model\n",
    "IMAGE_PATH = r'D:\\DL_data\\Accuracy\\Stage 2 Ensemble\\Test_images'\n",
    "\n",
    "# set confidence score threshold; for this SSD confidence score 0.3+ is generally good\n",
    "conf_thd = 0.28\n",
    "\n",
    "######## TFOD block #########\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-24')).expect_partial()   # Change check point number to latest version\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])\n",
    "\n",
    "######## NMS block, to remove redundant bboxes  ########\n",
    "def nms(rects, thd=0.5):    # rects here probably refer to detections\n",
    "    \"\"\"\n",
    "    Filter rectangles\n",
    "    rects is array of oblects ([x1,y1,x2,y2], confidence, class)\n",
    "    thd - intersection threshold (intersection divides min square of rectange)    # same as IoU?\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    remove = [False] * len(rects)\n",
    "    for i in range(0, len(rects) - 1):\n",
    "        if remove[i]:\n",
    "            continue\n",
    "        inter = [0.0] * len(rects)\n",
    "        for j in range(i, len(rects)):\n",
    "            if remove[j]:\n",
    "                continue\n",
    "            inter[j] = intersection(rects[i][0], rects[j][0]) / min(square(rects[i][0]), square(rects[j][0]))\n",
    "        max_prob = 0.0\n",
    "        max_idx = 0\n",
    "        for k in range(i, len(rects)):\n",
    "            if inter[k] >= thd:\n",
    "                if rects[k][1] > max_prob:\n",
    "                    max_prob = rects[k][1]\n",
    "                    max_idx = k\n",
    "        for k in range(i, len(rects)):\n",
    "            if (inter[k] >= thd) & (k != max_idx):\n",
    "                remove[k] = True\n",
    "    for k in range(0, len(rects)):\n",
    "        if not remove[k]:\n",
    "            out.append(rects[k])\n",
    "    boxes = [box[0] for box in out]\n",
    "    scores = [score[1] for score in out]\n",
    "    classes = [cls[2] for cls in out]\n",
    "    return boxes, scores, classes\n",
    "\n",
    "def intersection(rect1, rect2):\n",
    "    \"\"\"\n",
    "    Calculates square of intersection of two rectangles\n",
    "    rect: list with coords of top-right and left-boom corners [x1,y1,x2,y2]\n",
    "    return: square of intersection\n",
    "    \"\"\"\n",
    "    x_overlap = max(0, min(rect1[2], rect2[2]) - max(rect1[0], rect2[0]));\n",
    "    y_overlap = max(0, min(rect1[3], rect2[3]) - max(rect1[1], rect2[1]));\n",
    "    overlapArea = x_overlap * y_overlap;\n",
    "    return overlapArea\n",
    "\n",
    "def square(rect):\n",
    "    \"\"\" Calculates square of rectangle \"\"\"\n",
    "    return abs(rect[2] - rect[0]) * abs(rect[3] - rect[1])\n",
    "\n",
    "def predictions_above_confidence(boxes_nms, scores_nms, labels_nms, conf_thd):\n",
    "    boxes_final, scores_final, labels_final = [], [], []     # create empty placeholder lists\n",
    "    for pred in zip(boxes_nms, scores_nms, labels_nms):\n",
    "        b, s, l = pred    # unpack predicted boxes, score, label\n",
    "        if s >= conf_thd:    # select boxes if confidence > threshold\n",
    "            boxes_final.append(b)\n",
    "            scores_final.append(s)\n",
    "            labels_final.append(l)\n",
    "    return boxes_final, scores_final, labels_final\n",
    "\n",
    "########  Write to txt block  ########\n",
    "def write_predictions_txt(boxes_list, scores_list, labels_list, image_name):\n",
    "    # choose output path\n",
    "    out_path = r'D:\\DL_data\\Accuracy\\Stage 2 Ensemble\\cn'\n",
    "    \n",
    "    # create and open a txt file\n",
    "    # parsed arg image_name has no file extension\n",
    "    with open(os.path.join(out_path, image_name+'.txt'), 'w') as f:    # txt needs to have same name as input image/annotation\n",
    "#         lines = []\n",
    "        # loop thru all predicted boxes for this image\n",
    "        for box, score, label in zip(boxes_list, scores_list, labels_list):\n",
    "            y1, x1, y2, x2 = box    # confirmed format of TFOD predictions\n",
    "            # convert into yolo [x,y,w,h] in RELATIVE numbers\n",
    "            cx = (x1 + x2) / 2    # x-center\n",
    "            cy = (y1 + y2) / 2    # y-center\n",
    "            w = x2 - x1    # width\n",
    "            h = y2 - y1    # height\n",
    "            line = str(label)+' '+f'{score:.5f}'+' '+str(cx)+' '+str(cy)+' '+str(w)+' '+str(h)+'\\n'\n",
    "            f.write(line)\n",
    "\n",
    "########  Write to xml block  ########\n",
    "def write_predictions_xml(boxes_list, labels_list, width, height, image_name):\n",
    "    # hard code the label names, so we don't have to read files; and names won't change\n",
    "    label_names = [ # 23 road mark classes\n",
    "      {'name':'25', 'id':1}, {'name':'30', 'id':2}, {'name':'35', 'id':3}, {'name':'40', 'id':4},\n",
    "      {'name':'45', 'id':5}, {'name':'50', 'id':6}, {'name':'bike', 'id':7}, {'name':'bus', 'id':8},\n",
    "      {'name':'diamond', 'id':9}, {'name':'F', 'id':10}, {'name':'FL', 'id':11}, {'name':'FR', 'id':12},\n",
    "      {'name':'KC', 'id':13}, {'name':'FLR', 'id':14}, {'name':'L', 'id':15}, {'name':'ped', 'id':16},\n",
    "      {'name':'rail', 'id':17}, {'name':'R', 'id':18}, {'name':'school', 'id':19}, {'name':'signal', 'id':20},\n",
    "      {'name':'stop', 'id':21}, {'name':'xing', 'id':22}, {'name':'yield', 'id':23},\n",
    "       # 9 helper classes\n",
    "      {'name':'biker', 'id':24}, {'name':'car', 'id':25}, {'name':'pedestrian', 'id':26},\n",
    "      {'name':'traffic_light', 'id':27}, {'name':'truck', 'id':28}, {'name':'stop_sign', 'id':29},\n",
    "      {'name':'yield_sign', 'id':30}, {'name':'school_sign', 'id':31}, {'name':'ped_sign', 'id':32} ]\n",
    "\n",
    "    \n",
    "    \"\"\"  Set output folder below:  \"\"\"\n",
    "    outpath = r'D:\\DL_data\\Accuracy\\Stage 2 Ensemble\\cn'    #### REMEMBER TO UPDATE THIS\n",
    "    \n",
    "#     img= cv2.imread(image_path)    # read image file from another folder\n",
    "#     height, width, channels = img.shape\n",
    "    node_root = Element('annotation')\n",
    "    node_folder = SubElement(node_root, 'folder')\n",
    "    node_folder.text = 'folder'    # customize what you want the 'folder' line to say\n",
    "    node_filename = SubElement(node_root, 'filename')\n",
    "    img_name = image_name    # will set the image name as the image_name parsed to this fn\n",
    "    node_filename.text = image_name\n",
    "    node_source= SubElement(node_root, 'source')\n",
    "    node_database = SubElement(node_source, 'database')\n",
    "    node_database.text = 'Predictions from Custom Models'    # customize what you want to appear under 'database'\n",
    "    node_size = SubElement(node_root, 'size')\n",
    "    node_width = SubElement(node_size, 'width')\n",
    "    node_width.text = str(width)\n",
    "    node_height = SubElement(node_size, 'height')\n",
    "    node_height.text = str(height)\n",
    "    node_depth = SubElement(node_size, 'depth')\n",
    "    node_depth.text = str(channels)\n",
    "    node_segmented = SubElement(node_root, 'segmented')\n",
    "    node_segmented.text = '0'\n",
    "    # now we turn boxes_list and labels_list into \n",
    "    # boxes_formatted = [ [class, x1, y1, x2, y2],\n",
    "    #                     [class, x1, y1, x2, y2], ...]     should be x1, y1, x2, y2 but order can be adjusted later\n",
    "    boxes_formatted = []    \n",
    "    for box, label in zip(boxes_final, labels_final):\n",
    "        y1, x1, y2, x2 = box    # this is the correct format of TFOD predicted boxes\n",
    "        boxes_formatted.append([label, x1, y1, x2, y2])    # change format to what we want\n",
    "    for box in boxes_formatted:    # loop thru each detected box\n",
    "        node_object = SubElement(node_root, 'object')\n",
    "        node_name = SubElement(node_object, 'name')\n",
    "        node_name.text = label_names[box[0]]['name']    # need to translate label from int to real label name\n",
    "        node_pose = SubElement(node_object, 'pose')\n",
    "        node_pose.text = 'Unspecified'\n",
    "        node_truncated = SubElement(node_object, 'truncated')\n",
    "        node_truncated.text = '0'\n",
    "        node_difficult = SubElement(node_object, 'difficult')\n",
    "        node_difficult.text = '0'\n",
    "        node_bndbox = SubElement(node_object, 'bndbox')    # start to write bbox coord in json format\n",
    "        \n",
    "        node_xmin = SubElement(node_bndbox, 'xmin')\n",
    "        node_xmin.text = str(int(box[1] * width))      # remember to do absolute coordinates for voc xml format\n",
    "        node_ymin = SubElement(node_bndbox, 'ymin')\n",
    "        node_ymin.text = str(int(box[2] * height))\n",
    "        node_xmax = SubElement(node_bndbox, 'xmax')\n",
    "        node_xmax.text =  str(int(box[3] * width))\n",
    "        node_ymax = SubElement(node_bndbox, 'ymax')\n",
    "        node_ymax.text = str(int(box[4] * height))\n",
    "    xml = tostring(node_root, pretty_print=True)    # print progress in command prompt?\n",
    "#     f =  open(outpath % image_name.split('.')[0], \"wb\")\n",
    "#     f = open(os.path.join('outputs', image_name.split('.')[0] + '_SSD' + '.xml'), \"wb\")    # customize your xml file name\n",
    "    f = open(os.path.join(outpath, image_name.split('.')[0] + '_CN' + '.xml'), \"wb\")\n",
    "    f.write(xml)\n",
    "    f.close()\n",
    "\n",
    "########  Functional code block  ########\n",
    "# loop thru all images in image_path\n",
    "for file in os.listdir(IMAGE_PATH):\n",
    "    image_name = file.split('.')[0]    # extract file name without file extension\n",
    "\n",
    "    # TFOD model , run inference\n",
    "    img = cv2.imread( os.path.join(IMAGE_PATH, file) )\n",
    "    height, width, channels = img.shape\n",
    "    image_np = np.array(img)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    \n",
    "    # Extract TFOD output\n",
    "    boxes_list = detections['detection_boxes']\n",
    "    scores_list = detections['detection_scores']  \n",
    "    labels_list = [int(i) for i in detections['detection_classes']] # somehow TFOD returns float for predicted classes, change it to int\n",
    "    \n",
    "#     # prepare data for NMS; rects is array of oblects ([x1,y1,x2,y2], confidence, class)\n",
    "    rectangles = [(b, s, l) for (b, s, l) in zip(boxes_list, scores_list, labels_list)]\n",
    "    \n",
    "#     # run NMS non-max suppression\n",
    "    boxes_nms, scores_nms, labels_nms = nms(rectangles)\n",
    "    \n",
    "#     # filer out predictions lower than confidence threshold\n",
    "    boxes_final, scores_final, labels_final = predictions_above_confidence(boxes_nms, scores_nms, labels_nms, conf_thd)\n",
    "\n",
    "#     # call write fn to write predictions into xml files\n",
    "#     write_predictions_xml(boxes_final, labels_final, width, height, file)\n",
    "                   \n",
    "    # write predictions to txt file as required by review_object_detection_metrics\n",
    "    write_predictions_txt(boxes_final, scores_final, labels_final, image_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t3",
   "language": "python",
   "name": "t3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
