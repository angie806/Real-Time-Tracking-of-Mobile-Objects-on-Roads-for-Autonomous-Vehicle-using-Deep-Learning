{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d70f937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n2 stage ensemble for object detection models.\\n\\nStage 1:\\n- For each test image:\\n- Run inference using our 4 models, store outputs.\\n- Convert outputs to EB format, \\n    by calling read_RODM_pred() for each model output.\\n    Append fn outputs to master lists.\\n- Run weighted boxes fusion (concensus/majority voting) on master lists.\\n- Store ensemble output to new txt file in RODM format.\\n- Show ensemble pictures.\\n- Run RODM on ensemble output to calculate mAP.\\n\\nStage 2:\\n- For each test image:\\n- Run inference using stock YOLOv4 trained on COCO, store outputs\\n    use 'Get YOLO4 output.ipynb' to convert YOLOv4 output to RODM format.\\n- Gather ensemble output from Stage 1, and YOLOv4 converted output\\n- Apply ensemble (affirmative/or method) using NMS function in EB.\\n- Store stage 2 ensemble output to new txt files.\\n- Show stage 2 ensemble pictures.\\n- No need to run RODM and calculate mAP. It's impossible because test data isn't annotated for 80 COCO classes.\\n\\nSome Notes:\\n- Enselbme Boxes input format: [x1, y1, x2, y2] normalized.\\n- Review Object Detection Metrics input format: [class_id, confidence, x, y, w, h] where coords are normalized.\\n- NMW non maximum weighted is a different NMS, where for each detection all boxes are considered, and a new weighted average\\n    box is created and original boxes discarded.\\n    \\nQuestoin:\\nEB only supports NMS, NMW, WFB, and not really affirmative/or method.\\nSo we use the same WFB function for both stages?\\n\\nInput Directories:\\n- All folders below are located in D:\\\\DL_data\\\\Accuracy- Custom YOLOv4 predictions: YOLO_test_output\\n- Custom CenterNet predictions: CenterNet_predictions_100bboxes  (100 bboxes, no NMS, no confidence filter)\\n- Custom EfficientDet predicitions: Eff_test_results\\n- Custom SSD predictions: SSD_predictions_100bboxes  (100 bboxes, no NMS, no confidence filter)\\n- Stock YOLOv4 predictions:\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "2 stage ensemble for object detection models.\n",
    "\n",
    "Without processing power to run all 4 models at the same time, so we propose an alternative:\n",
    "we run 4 models on the same test data separately, gather the output and ensemble.\n",
    "\n",
    "Stage 1:\n",
    "- For each test image:\n",
    "- Run inference using our 4 models, store outputs.\n",
    "- Convert outputs to EB format, \n",
    "    by calling read_RODM_pred() for each model output.\n",
    "    Append fn outputs to master lists.\n",
    "- Apply ensemble (concensus/majority voting) on master lists.\n",
    "- Store ensemble output to new txt file in RODM format.\n",
    "- Show ensemble pictures.\n",
    "- Run RODM on ensemble output to calculate mAP.\n",
    "\n",
    "Stage 2:\n",
    "- For each test image:\n",
    "- Run inference using stock YOLOv4 trained on COCO, store outputs\n",
    "    use 'Get YOLO4 output.ipynb' to convert YOLOv4 output to RODM format.\n",
    "- Gather ensemble output from Stage 1, and YOLOv4 converted output\n",
    "- Apply ensemble (affirmative/or method) function in EB.\n",
    "- Store stage 2 ensemble output to new txt files.\n",
    "- Show stage 2 ensemble pictures.\n",
    "- No need to run RODM and calculate mAP. It's impossible because test data isn't annotated for 80 COCO classes.\n",
    "\n",
    "Some Notes:\n",
    "- Enselbme Boxes input format: [x1, y1, x2, y2] normalized.\n",
    "- Review Object Detection Metrics input format: [class_id, confidence, x, y, w, h] where coords are normalized.\n",
    "- NMW non maximum weighted is a different NMS, where for each detection all boxes are considered, and a new weighted average\n",
    "    box is created and original boxes discarded.\n",
    "- Test dataset should have 1497 images, excluding B111.jpg, or B111.txt for predictions.\n",
    "    \n",
    "\n",
    "Input Directories:\n",
    "- All folders below are located in D:\\DL_data\\Accuracy\\\n",
    "- Custom YOLOv4 predictions: YOLO_test_output\n",
    "- Custom CenterNet predictions: CenterNet_predictions_100bboxes  (100 bboxes, no NMS, no confidence filter)\n",
    "  - after NMS and confidence filter: CenterNet_nms_conf\n",
    "- Custom EfficientDet predicitions: Eff_test_results\n",
    "- Custom SSD predictions: SSD_predictions_100bboxes  (100 bboxes, no NMS, no confidence filter)\n",
    "  - after NMS and confidence filter: SSD_nms_conf\n",
    "- Stock YOLOv4 predictions:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ffd0c",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92d764da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from ensemble_boxes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b0922b",
   "metadata": {},
   "source": [
    "#### show image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d5dd5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(im, name='image'):\n",
    "    resized = ResizeWithAspectRatio(im, height=900)    # Can resize by width or height\n",
    "    cv2.imshow(name, resized)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "172bf2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to resize cv2 imshow window\n",
    "def ResizeWithAspectRatio(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "    return cv2.resize(image, dim, interpolation=inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c8ca06",
   "metadata": {},
   "source": [
    "#### show boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b558bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_colors(names):\n",
    "    \"\"\"\n",
    "    Create a dict with one random BGR color for each\n",
    "    class name\n",
    "    \"\"\"\n",
    "    return {name: (\n",
    "        random.randint(0, 255),\n",
    "        random.randint(0, 255),\n",
    "        random.randint(0, 255)) for name in names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f246d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_boxes(boxes_list, scores_list, labels_list, image_path):  \n",
    "    \n",
    "    # to correctly call color fn, unpack labels_list\n",
    "    labels_unpacked =[]\n",
    "    for lst in labels_list:\n",
    "        labels_unpacked.extend(lst)\n",
    "        \n",
    "    color_list = class_colors(labels_unpacked)    # generate random color for each predicted class\n",
    "    \n",
    "    image = cv2.imread(image_path)    # load image file\n",
    "    height, width = image.shape[:2]    # get image size\n",
    "    thickness = 2    # thickness of bbox border\n",
    "    \n",
    "    for i in range(len(boxes_list)):    # loop thru each predicted image?\n",
    "        for j in range(len(boxes_list[i])):    # loop thru each bbox for each image?\n",
    "            x1 = int(width * boxes_list[i][j][0])\n",
    "            y1 = int(height * boxes_list[i][j][1])\n",
    "            x2 = int(width * boxes_list[i][j][2])\n",
    "            y2 = int(height * boxes_list[i][j][3])\n",
    "            lbl = labels_list[i][j]    # this is the predicted class value in int\n",
    "            \n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), color_list[lbl], thickness)    # now we can call color_list[class #]\n",
    "            cv2.putText(image, '{} [{:.2f}]'.format(label_names[lbl]['name'], float(scores_list[i][j])),\n",
    "                       (x1, y2-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                       color_list[lbl], 1)\n",
    "    show_image(image)\n",
    "    \n",
    "    #### if need to resize cv2 show window size, see 9. 32 classes scratch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "64b059d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard coded here, so that we don't need to read any file to get class names\n",
    "# notice this is a list of dictionaries\n",
    "label_names = [ # 23 road mark classes\n",
    "          {'name':'25', 'id':1}, {'name':'30', 'id':2}, \n",
    "          {'name':'35', 'id':3}, {'name':'40', 'id':4},\n",
    "          {'name':'45', 'id':5}, {'name':'50', 'id':6},\n",
    "          {'name':'bike', 'id':7}, {'name':'bus', 'id':8},\n",
    "          {'name':'diamond', 'id':9}, {'name':'F', 'id':10},\n",
    "          {'name':'FL', 'id':11}, {'name':'FR', 'id':12},\n",
    "          {'name':'KC', 'id':13}, {'name':'FLR', 'id':14},\n",
    "          {'name':'L', 'id':15}, {'name':'ped', 'id':16},\n",
    "          {'name':'rail', 'id':17}, {'name':'R', 'id':18},\n",
    "          {'name':'school', 'id':19},\n",
    "          {'name':'signal', 'id':20}, {'name':'stop', 'id':21},\n",
    "          {'name':'xing', 'id':22}, {'name':'yield', 'id':23},\n",
    "    \n",
    "           # 9 helper classes\n",
    "          {'name':'biker', 'id':24}, {'name':'car', 'id':25},\n",
    "          {'name':'pedestrian', 'id':26}, {'name':'traffic_light', 'id':27},\n",
    "          {'name':'truck', 'id':28}, {'name':'stop_sign', 'id':29},\n",
    "          {'name':'yield_sign', 'id':30}, {'name':'school_sign', 'id':31},\n",
    "          {'name':'ped_sign', 'id':32},\n",
    "    \n",
    "# 80 COCO classes\n",
    "    {'name': 'person', 'id':33}, {'name': 'bicycle', 'id':34}, \n",
    "    {'name': 'car2', 'id':34},    # merge 2 'car' categories, replace this with dummy class\n",
    "    {'name': 'motorbike', 'id':36},\n",
    "    {'name': 'aeroplane', 'id':37}, {'name': 'bus', 'id':38}, {'name': 'train', 'id':39}, \n",
    "    {'name': 'truck2', 'id':40},    # merge truck and replace with dummy class\n",
    "    {'name': 'boat', 'id':41}, {'name': 'traffic light', 'id':42}, {'name': 'fire hydrant', 'id':43}, {'name': 'stop sign', 'id':44}, \n",
    "    {'name': 'parking meter', 'id':45}, {'name': 'bench', 'id':46}, {'name': 'bird', 'id':47}, {'name': 'cat', 'id':48},\n",
    "    {'name': 'dog', 'id':49}, {'name': 'horse', 'id':50}, {'name': 'sheep', 'id':51}, {'name': 'cow', 'id':52}, \n",
    "    {'name': 'elephant', 'id':53}, {'name': 'bear', 'id':54}, {'name': 'zebra', 'id':55}, {'name': 'giraffe', 'id':56},\n",
    "    {'name': 'backpack', 'id':57}, {'name': 'umbrella', 'id':58}, {'name': 'handbag', 'id':59}, {'name': 'tie', 'id':60}, \n",
    "    {'name': 'suitcase', 'id':61}, {'name': 'frisbee', 'id':62}, {'name': 'skis', 'id':63}, {'name': 'snowboard', 'id':64},\n",
    "    {'name': 'sports ball', 'id':65}, {'name': 'kite', 'id':66}, {'name': 'baseball bat', 'id':67}, {'name': 'baseball glove', 'id':68},\n",
    "    {'name': 'skateboard', 'id':69}, {'name': 'surfboard', 'id':70}, {'name': 'tennis racket', 'id':71}, {'name': 'bottle', 'id':72},\n",
    "    {'name': 'wine glass', 'id':73}, {'name': 'cup', 'id':74}, {'name': 'fork', 'id':75}, {'name': 'knife', 'id':76},\n",
    "    {'name': 'spoon', 'id':77}, {'name': 'bowl', 'id':78}, {'name': 'banana', 'id':79}, {'name': 'apple', 'id':80},\n",
    "    {'name': 'sandwich', 'id':81}, {'name': 'orange', 'id':82}, {'name': 'broccoli', 'id':83}, {'name': 'carrot', 'id':84},\n",
    "    {'name': 'hot dog', 'id':85}, {'name': 'pizza', 'id':86}, {'name': 'donut', 'id':87}, {'name': 'cake', 'id':88},\n",
    "    {'name': 'chair', 'id':89}, {'name': 'sofa', 'id':90}, {'name': 'pottedplant', 'id':91}, {'name': 'bed', 'id':92},\n",
    "    {'name': 'diningtable', 'id':93}, {'name': 'toilet', 'id':94}, {'name': 'tvmonitor', 'id':95}, {'name': 'laptop', 'id':96},\n",
    "    {'name': 'mouse', 'id':97}, {'name': 'remote', 'id':98}, {'name': 'keyboard', 'id':99}, {'name': 'cell phone', 'id':100},\n",
    "    {'name': 'microwave', 'id':101}, {'name': 'oven', 'id':102}, {'name': 'toaster', 'id':103}, {'name': 'sink', 'id':104},\n",
    "    {'name': 'refrigerator', 'id':105}, {'name': 'book', 'id':106}, {'name': 'clock', 'id':107}, {'name': 'vase', 'id':108},\n",
    "    {'name': 'scissors', 'id':109}, {'name': 'teddy bear', 'id':110}, {'name': 'hair drier', 'id':111}, {'name': 'toothbrush', 'id':112} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6dc5c",
   "metadata": {},
   "source": [
    "#### Separate NMS and confidence filter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb43a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########  NMS block, to remove redundant bboxes  ########\n",
    "def nms(rects, thd=0.5):    # rects here probably refer to detections\n",
    "    \"\"\"\n",
    "    Filter rectangles\n",
    "    rects is array of oblects ([x1,y1,x2,y2], confidence, class)\n",
    "    thd - intersection threshold (intersection divides min square of rectange)    # same as IoU?\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    remove = [False] * len(rects)\n",
    "    for i in range(0, len(rects) - 1):\n",
    "        if remove[i]:\n",
    "            continue\n",
    "        inter = [0.0] * len(rects)\n",
    "        for j in range(i, len(rects)):\n",
    "            if remove[j]:\n",
    "                continue\n",
    "            inter[j] = intersection(rects[i][0], rects[j][0]) / min(square(rects[i][0]), square(rects[j][0]))\n",
    "        max_prob = 0.0\n",
    "        max_idx = 0\n",
    "        for k in range(i, len(rects)):\n",
    "            if inter[k] >= thd:\n",
    "                if rects[k][1] > max_prob:\n",
    "                    max_prob = rects[k][1]\n",
    "                    max_idx = k\n",
    "        for k in range(i, len(rects)):\n",
    "            if (inter[k] >= thd) & (k != max_idx):\n",
    "                remove[k] = True\n",
    "    for k in range(0, len(rects)):\n",
    "        if not remove[k]:\n",
    "            out.append(rects[k])\n",
    "    boxes = [box[0] for box in out]\n",
    "    scores = [score[1] for score in out]\n",
    "    classes = [cls[2] for cls in out]\n",
    "    return boxes, scores, classes\n",
    "\n",
    "def intersection(rect1, rect2):\n",
    "    \"\"\"\n",
    "    Calculates square of intersection of two rectangles\n",
    "    rect: list with coords of top-right and left-boom corners [x1,y1,x2,y2]\n",
    "    return: square of intersection\n",
    "    \"\"\"\n",
    "    x_overlap = max(0, min(rect1[2], rect2[2]) - max(rect1[0], rect2[0]));\n",
    "    y_overlap = max(0, min(rect1[3], rect2[3]) - max(rect1[1], rect2[1]));\n",
    "    overlapArea = x_overlap * y_overlap;\n",
    "    return overlapArea\n",
    "\n",
    "def square(rect):\n",
    "    \"\"\" Calculates square of rectangle \"\"\"\n",
    "    return abs(rect[2] - rect[0]) * abs(rect[3] - rect[1])\n",
    "\n",
    "########  Confidence Filter block  ########\n",
    "def predictions_above_confidence(boxes_nms, scores_nms, labels_nms, conf_thd):\n",
    "    boxes_final, scores_final, labels_final = [], [], []     # create empty placeholder lists\n",
    "    for pred in zip(boxes_nms, scores_nms, labels_nms):\n",
    "        b, s, l = pred    # unpack predicted boxes, score, label\n",
    "        if s >= conf_thd:    # select boxes if confidence > threshold\n",
    "            boxes_final.append(b)\n",
    "            scores_final.append(s)\n",
    "            labels_final.append(l)\n",
    "    return boxes_final, scores_final, labels_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa3d30",
   "metadata": {},
   "source": [
    "#### Write ensemble/NMS output to .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d927870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### parse ensemble master lists to this fn, to create new txt files\n",
    "\n",
    "def write_predictions_txt(boxes_list, scores_list, labels_list, out_path, file_name):\n",
    "    # create and open a txt file\n",
    "    with open(os.path.join(out_path, file_name), 'w') as f:    # txt needs to have same name as input image/annotation\n",
    "        # loop thru all predicted boxes for this image\n",
    "        for box, score, label in zip(boxes_list, scores_list, labels_list):\n",
    "            x1, y1, x2, y2 = box    # This is the format of RODM\n",
    "            # convert into yolo [x,y,w,h] in RELATIVE numbers\n",
    "            cx = (x1 + x2) / 2    # x-center\n",
    "            cy = (y1 + y2) / 2    # y-center\n",
    "            w = x2 - x1    # width\n",
    "            h = y2 - y1    # height\n",
    "            line = str(int(label))+' '+f'{score:.5f}'+' '+str(cx)+' '+str(cy)+' '+str(w)+' '+str(h)+'\\n'\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e7e051",
   "metadata": {},
   "source": [
    "#### Convert input formats to fit ensemble_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d49ba551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read each file parsed into this fn\n",
    "# and convert from RODM txt format [x,y,w,h] to EB format[x1,y1,x2,y2]\n",
    "\n",
    "def load_pred(file):\n",
    "    # instantiate placeholder vars\n",
    "    boxes_list, scores_list, labels_list = [], [], []\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        for line in f.readlines():    # read each line\n",
    "            # extract info for each predicted box\n",
    "            line = line.split()    # make line elements iterable\n",
    "            labels_list.append(int(line[0]))    # class id should be int\n",
    "            scores_list.append(float(line[1]))    # confidence score shoulbe be float\n",
    "\n",
    "            # convert xywh to [x1, y1, x2, y2]\n",
    "            x, y, w, h = float(line[2]), float(line[3]), float(line[4]), float(line[5])\n",
    "            x1 = x - w/2\n",
    "            y1 = y - h/2\n",
    "            x2 = x + w/2\n",
    "            y2 = y + h/2\n",
    "            boxes_list.append([x1, y1, x2, y2])\n",
    "    \n",
    "    return boxes_list, scores_list, labels_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2eeef7",
   "metadata": {},
   "source": [
    "#### EB WBF Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e1db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_wbf_2_models(image_path, iou_thr=0.55, draw_image=True):\n",
    "    \"\"\"\n",
    "    This example shows how to ensemble boxes from 2 models using WBF method    \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    boxes_list = [\n",
    "        [\n",
    "            [0.00, 0.51, 1.00, 0.91],\n",
    "            [0.10, 0.31, 0.71, 0.61],\n",
    "            [0.01, 0.32, 0.83, 0.93],\n",
    "            [0.02, 0.53, 0.11, 0.94],\n",
    "            [0.03, 0.24, 0.12, 0.35],\n",
    "        ],\n",
    "        [\n",
    "            [0.04, 0.56, 0.84, 0.92],\n",
    "            [0.12, 0.33, 0.72, 0.64],\n",
    "            [0.38, 0.66, 0.79, 0.95],\n",
    "            [0.08, 0.49, 0.21, 0.89],\n",
    "        ],\n",
    "    ]\n",
    "    scores_list = [ [0.9, 0.8, 0.2, 0.4, 0.7],\n",
    "                    [0.5, 0.8, 0.7, 0.3] ]\n",
    "    labels_list = [ [10, 28, 6, 1, 2],\n",
    "                    [5, 7, 9, 11] ]\n",
    "    weights = [2, 1]\n",
    "    \n",
    "    # show image before WBF\n",
    "    image_path = image_path\n",
    "    if draw_image:\n",
    "        # added image_path\n",
    "        show_boxes(boxes_list, scores_list, labels_list, image_path)\n",
    "    \n",
    "    # apply WBF\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list, weights=weights, iou_thr=iou_thr, skip_box_thr=0.0)\n",
    "    \n",
    "    # show image after WBF\n",
    "    if draw_image:\n",
    "        # added image_path\n",
    "        show_boxes([boxes], [scores], [labels.astype(np.int32)], image_path)\n",
    "\n",
    "    # print bboxes after WBF\n",
    "    print(len(boxes))\n",
    "    print(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86570204",
   "metadata": {},
   "source": [
    "#### Optional: apply NMS and confidence filter on model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "848f0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note: It is better to run NMS and confidence filter when running inference.\n",
    "\n",
    "\"\"\" \n",
    "Apply NMS and confidence filter to default 100 bbox predictions for SSD.\n",
    "And write processed predictions to txt files.\n",
    "So we have 2 sets of predictions for SSD.\n",
    "\"\"\"\n",
    "\n",
    "# where SSD default 100 bbox predictions are stored\n",
    "pred_path = r'D:\\DL_data\\Accuracy\\SSD_predictions_100bboxes'\n",
    "\n",
    "# where do you want to store processed predictions\n",
    "out_path = r'D:\\DL_data\\Accuracy\\SSD_nms_conf'\n",
    "\n",
    "# set confidence threshold\n",
    "conf_thd = 0.3    # for SSD, 0.3 is good in general\n",
    "\n",
    "# loop thru all predictions\n",
    "for file in os.listdir(pred_path):\n",
    "    image_name = file.split('.')[0]    # extract file name without file extension\n",
    "    \n",
    "    # open prediction txt file\n",
    "    with open( os.path.join(pred_path, file), 'r') as f:\n",
    "        boxes_list, scores_list, labels_list = [], [], []    # placeholders\n",
    "        \n",
    "        for line in f.readlines():    # read each line\n",
    "            line = line.split()    # make line elements iterable\n",
    "            label = int(line[0])\n",
    "            score = float(line[1])\n",
    "            x, y, w, h = float(line[2]), float(line[3]), float(line[4]), float(line[5])\n",
    "            \n",
    "            boxes_list.append([x, y, w, h])\n",
    "            scores_list.append(score)\n",
    "            labels_list.append(label)\n",
    "            \n",
    "    # generate rectangles for nms fn\n",
    "    rectangles = [(b, s, l) for (b, s, l) in zip(boxes_list, scores_list, labels_list)]\n",
    "\n",
    "    # apply NMS to predictions\n",
    "    boxes_nms, scores_nms, labels_nms = nms(rectangles)    # dafault IoU threshold = 0.5\n",
    "    \n",
    "    # apply confidence filter \n",
    "    boxes_final, scores_final, labels_final = predictions_above_confidence(boxes_nms, scores_nms, labels_nms, conf_thd)\n",
    "\n",
    "    # write processed predictions to new txt files\n",
    "    write_predictions_txt(boxes_final, scores_final, labels_final, image_name, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "898958e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### confidence filter\n",
    "\n",
    "def predictions_above_confidence(boxes_nms, scores_nms, labels_nms, conf_thd):\n",
    "    boxes_final, scores_final, labels_final = [], [], []     # create empty placeholder lists\n",
    "    for pred in zip(boxes_nms, scores_nms, labels_nms):\n",
    "        b, s, l = pred    # unpack predicted boxes, score, label\n",
    "        if s >= conf_thd:    # select boxes if confidence > threshold\n",
    "            boxes_final.append(b)\n",
    "            scores_final.append(s)\n",
    "            labels_final.append(l)\n",
    "    return boxes_final, scores_final, labels_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44439c5e",
   "metadata": {},
   "source": [
    "## Stage 1 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dae278a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note: Stage 1 code needs to update paths, because folder structure has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59389a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEnsemble pseudo code\\n\\nfor image in folder:\\n    create master lists\\n    \\n    for model in models:\\n        get predictions\\n        append to master lists\\n        \\n    do ensemble \\n    write output to new txt files\\n\\n# below may be done thru another program/notebook\\ncalculate mAP\\nshow some images\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ensemble pseudo code\n",
    "\n",
    "for image in folder:\n",
    "    create master lists\n",
    "    \n",
    "    for model in models:\n",
    "        get predictions\n",
    "        append to master lists\n",
    "        \n",
    "    do ensemble \n",
    "    write output to new txt files\n",
    "\n",
    "# below may be done thru another program/notebook\n",
    "calculate mAP\n",
    "show some images\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "016475b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### locate model predictions txt files for each model\n",
    "\n",
    "# custom YOLOv4\n",
    "path_YOLO4 = r'D:\\DL_data\\Accuracy\\YOLO_test_output'\n",
    "\n",
    "# custom EfficientDet\n",
    "path_ED = r'D:\\DL_data\\Accuracy\\Eff_test_results'\n",
    "\n",
    "# custom SSD mobilenet 640\n",
    "path_SSD = r'D:\\DL_data\\Accuracy\\SSD_nms_conf'    # with NMS and confidence filter applied\n",
    "\n",
    "# custom CenterNet Hourglass 512\n",
    "path_CN = r'D:\\DL_data\\Accuracy\\CenterNet_nms_conf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43f26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose where to store ensemble output txt files\n",
    "out_path = r'D:\\DL_data\\Accuracy\\Ensemble_Output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35de1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### some params for Weighted Boxes Fusion should you want to tweek\n",
    "\n",
    "# weights for each model:\n",
    "weights = [2, 1.5, 1, 1.5]    # here we assume the order is [Yolo4, EfficientDet, SSD, CenterNet]\n",
    "\n",
    "# IoU threshold\n",
    "iou_thr = 0.5    # use 0.5 for COCO mAP\n",
    "\n",
    "# confidence threshold, for confidence filter\n",
    "conf_thd = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b68398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Run this cell to generate ensemble results and write to txt files \"\"\"\n",
    "\n",
    "# generate a list of all images\n",
    "# since all models have predictions on the same test dataset, we can get this list from any 1 model\n",
    "all_img_preds = os.listdir(path_YOLO4)    # get list of file names without full path\n",
    "\n",
    "# gather paths for all 4 models\n",
    "model_paths = [path_YOLO4, path_ED, path_SSD, path_CN]\n",
    "\n",
    "# work on 1 image at a time\n",
    "for img_pred in all_img_preds:\n",
    "    # instantiate master lists\n",
    "    boxes_master = []\n",
    "    scores_master = []\n",
    "    labels_master = []\n",
    "    # note: img_pred is something like 'A101.txt'\n",
    "    \n",
    "    # for this image, gather predictions from all 4 models, model by model\n",
    "    for model_path in model_paths:\n",
    "        # instantiate placeholders for this model\n",
    "        boxes_model = []\n",
    "        scores_model = []\n",
    "        labels_model = []\n",
    "        \n",
    "        # locate the prediction txt file\n",
    "        file = os.path.join(model_path, img_pred)\n",
    "        # read prediction file\n",
    "        with open(file, 'r') as f:\n",
    "            # read each line in prediction file\n",
    "            for line in f.readlines():\n",
    "                line = line.split()    # make line elements iterable\n",
    "                labels_model.append(int(line[0]))    # class id should be int\n",
    "                scores_model.append(float(line[1]))    # confidence score shoulbe be float\n",
    "                \n",
    "                # convert xywh to [x1, y1, x2, y2]\n",
    "                x, y, w, h = float(line[2]), float(line[3]), float(line[4]), float(line[5])\n",
    "                x1 = x - w/2\n",
    "                y1 = y - h/2\n",
    "                x2 = x + w/2\n",
    "                y2 = y + h/2\n",
    "                boxes_model.append([x1, y1, x2, y2])\n",
    "                \n",
    "        # now gather all 4 model predictions for this image \n",
    "        boxes_master.append(boxes_model)\n",
    "        scores_master.append(scores_model)\n",
    "        labels_master.append(labels_model)\n",
    "\n",
    "    # apply ensemble to all 4 model predictions for this image\n",
    "    boxes_ensemble, scores_ensemble, labels_ensemble = weighted_boxes_fusion(boxes_master, scores_master, labels_master, weights=weights, iou_thr=iou_thr, skip_box_thr=0.0)\n",
    "    \n",
    "#     # apply NMS to remove redundant boxes\n",
    "#     boxes_e_nms, scores_e_nms, labels_e_nms = nms_method([boxes_ensemble], [scores_ensemble], [labels_ensemble], method=3, weights=weights, iou_thr=iou_thr, sigma=0.5, thresh=0.001)\n",
    "\n",
    "    # apply confidence filter\n",
    "    boxes_e_c, scores_e_c, labels_e_c = predictions_above_confidence(boxes_ensemble, scores_ensemble, labels_ensemble, conf_thd)\n",
    "\n",
    "    # write ensemble results to txt file, we use the same file name as predictions, just store to different folder        \n",
    "    write_predictions_txt(boxes_e_c, scores_e_c, labels_e_c, out_path, img_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f9d68",
   "metadata": {},
   "source": [
    "## Stage 2 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd2a59ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAs mentioned, we cannot calculate mAP for Stage 2, because our test data is not annotated for all 80 COCO classes.\\nHowever, we can show prediction images for Stage 2 ensemble model.\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "As mentioned, we cannot calculate mAP for Stage 2, because our test data is not annotated for all 80 COCO classes.\n",
    "However, we can show prediction images for Stage 2 ensemble model.\n",
    "\n",
    "Note: we are re-using the names of variables. \n",
    "So DO NOT skip/jump around when executing Stage 1 and Stage 2 code.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f59a0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather a new tiny test dataset (let's say 5 images)\n",
    "# and run all 4 models\n",
    "# ensemble the predictions (stage 1)\n",
    "# then run stock YOLOv4 on new tiny test dataset\n",
    "# ensemble this results and the stage 1 results\n",
    "# visualize stage 2 results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b7b48",
   "metadata": {},
   "source": [
    "#### set up paths for stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f614dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stage 2 test data location\n",
    "s2_img_path = r'D:\\DL_data\\Accuracy\\Stage_2_Ensemble\\Test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8941ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### locate model predictions txt files for each model\n",
    "\n",
    "# CUSTOM YOLOv4\n",
    "path_YOLO4 = r'D:\\DL_data\\Accuracy\\Stage_2_Ensemble\\custom_yolo4'\n",
    "\n",
    "# custom EfficientDet\n",
    "path_ED = r'D:\\DL_data\\Accuracy\\Stage_2_Ensemble\\efficientdet'\n",
    "\n",
    "# custom SSD mobilenet 640\n",
    "path_SSD = r'D:\\DL_data\\Accuracy\\Stage_2_Ensemble\\ssd'    # with NMS and confidence filter applied\n",
    "\n",
    "# custom CenterNet Hourglass 512\n",
    "path_CN = r'D:\\DL_data\\Accuracy\\Stage_2_Ensemble\\centernet'\n",
    "\n",
    "# STOCK YOLOv4\n",
    "path_stock_YOLO4 = r'D:\\DL_data\\Accuracy\\Stage_2_Ensemble\\stock_yolo4'\n",
    "\n",
    "# stage 1 ensemble output, for this new tiny test dataset\n",
    "stage1_output = r'D:\\DL_data\\Accuracy\\Stage_2_Ensemble\\stage1_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6247f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose where to store stage 2 output txt files\n",
    "stage2_output = r'D:\\DL_data\\Accuracy\\Stage_2_Ensemble\\stage2_output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b19707",
   "metadata": {},
   "source": [
    "#### visualize some model predictions before stage 1 ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea8e6dad",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\DL_data\\\\Accuracy\\\\Stage 2 Ensemble\\\\efficientdet\\\\9663077996_31dd326967_z.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-75a383fccbf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'9663077996_31dd326967_z'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mboxes_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_pred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_ED\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mshow_boxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mboxes_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mscores_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabels_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms2_img_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-db72276bd6ff>\u001b[0m in \u001b[0;36mload_pred\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mboxes_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# read each line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;31m# extract info for each predicted box\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\DL_data\\\\Accuracy\\\\Stage 2 Ensemble\\\\efficientdet\\\\9663077996_31dd326967_z.txt'"
     ]
    }
   ],
   "source": [
    "# show some stage prelim predictions\n",
    "\n",
    "# show SSD prediction on this image\n",
    "file_name = '9663077996_31dd326967_z'\n",
    "\n",
    "boxes_list, scores_list, labels_list = load_pred(os.path.join(path_ED,file_name+'.txt'))\n",
    "\n",
    "show_boxes([boxes_list], [scores_list], [labels_list], os.path.join(s2_img_path,file_name+'.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238b42f",
   "metadata": {},
   "source": [
    "#### do stage 2 ensemble for new tiny test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9add3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### now that we have predictions of new tiny test dataset from all 4 custom models + stock YOLOv4\n",
    "## we can proceed to do stage 1 ensemble for this test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9c6779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### some params for Weighted Boxes Fusion should you want to tweek\n",
    "\n",
    "# weights for each model:\n",
    "weights = [2, 1.5, 1, 1.5]    # here we assume the order is [Yolo4, EfficientDet, SSD, CenterNet]\n",
    "\n",
    "# IoU threshold\n",
    "iou_thr = 0.5    # use 0.5 for COCO mAP\n",
    "\n",
    "# confidence threshold, for confidence filter\n",
    "conf_thd = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3044b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Run this cell to generate ensemble results and write to txt files \"\"\"\n",
    "\n",
    "# generate a list of all images\n",
    "# since all models have predictions on the same test dataset, we can get this list from any 1 model\n",
    "all_img_preds = os.listdir(path_YOLO4)    # get list of file names without full path\n",
    "\n",
    "# gather paths for all 4 models\n",
    "model_paths = [path_YOLO4, path_ED, path_SSD, path_CN]\n",
    "\n",
    "# work on 1 image at a time\n",
    "for img_pred in all_img_preds:\n",
    "    # instantiate master lists\n",
    "    boxes_master = []\n",
    "    scores_master = []\n",
    "    labels_master = []\n",
    "    # note: img_pred is something like 'A101.txt'\n",
    "    \n",
    "    # for this image, gather predictions from all 4 models, model by model\n",
    "    for model_path in model_paths:\n",
    "        # instantiate placeholders for this model\n",
    "        boxes_model = []\n",
    "        scores_model = []\n",
    "        labels_model = []\n",
    "        \n",
    "        # locate the prediction txt file\n",
    "        file = os.path.join(model_path, img_pred)\n",
    "        # read prediction file\n",
    "        with open(file, 'r') as f:\n",
    "            # read each line in prediction file\n",
    "            for line in f.readlines():\n",
    "                line = line.split()    # make line elements iterable\n",
    "                labels_model.append(int(line[0]))    # class id should be int\n",
    "                scores_model.append(float(line[1]))    # confidence score shoulbe be float\n",
    "                \n",
    "                # convert xywh to [x1, y1, x2, y2]\n",
    "                x, y, w, h = float(line[2]), float(line[3]), float(line[4]), float(line[5])\n",
    "                x1 = x - w/2\n",
    "                y1 = y - h/2\n",
    "                x2 = x + w/2\n",
    "                y2 = y + h/2\n",
    "                boxes_model.append([x1, y1, x2, y2])\n",
    "                \n",
    "        # now gather all 4 model predictions for this image \n",
    "        boxes_master.append(boxes_model)\n",
    "        scores_master.append(scores_model)\n",
    "        labels_master.append(labels_model)\n",
    "\n",
    "    # apply ensemble to all 4 model predictions for this image\n",
    "    boxes_ensemble, scores_ensemble, labels_ensemble = weighted_boxes_fusion(boxes_master, scores_master, labels_master, weights=weights, iou_thr=iou_thr, skip_box_thr=0.0)\n",
    "    \n",
    "#     # apply NMS to remove redundant boxes\n",
    "#     boxes_e_nms, scores_e_nms, labels_e_nms = nms_method([boxes_ensemble], [scores_ensemble], [labels_ensemble], method=3, weights=weights, iou_thr=iou_thr, sigma=0.5, thresh=0.001)\n",
    "\n",
    "    # apply confidence filter\n",
    "    boxes_e_c, scores_e_c, labels_e_c = predictions_above_confidence(boxes_ensemble, scores_ensemble, labels_ensemble, conf_thd)\n",
    "\n",
    "    # write ensemble results to txt file, we use the same file name as predictions, just store to different folder        \n",
    "    write_predictions_txt(boxes_e_c, scores_e_c, labels_e_c, stage1_output, img_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64955261",
   "metadata": {},
   "source": [
    "#### visualize stage 1 ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "132c208b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2058486321_8c8fbcbcd7_z\n",
      "6828176341_3a23aa4623_z\n",
      "8288873861_a24b6b421a_z\n",
      "8302503786_8820161815_z\n",
      "9663077996_31dd326967_z\n",
      "A858\n",
      "B193\n",
      "B365\n"
     ]
    }
   ],
   "source": [
    "# show some stage 1 ensemble predictions\n",
    "\n",
    "# loop thru all test images\n",
    "eight_imgs = os.listdir(s2_img_path)\n",
    "for img in eight_imgs:\n",
    "#     print(img)\n",
    "    file_name = img.split('.')[0]\n",
    "    print(file_name)\n",
    "    \n",
    "    # convert RODM format to EB format\n",
    "    boxes_list, scores_list, labels_list = load_pred(os.path.join(stage1_output,file_name+'.txt'))\n",
    "\n",
    "    # visualize ensemble predictions for each image\n",
    "    show_boxes([boxes_list], [scores_list], [labels_list], os.path.join(s2_img_path,file_name+'.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa2f1f8",
   "metadata": {},
   "source": [
    "#### run stage 2 ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f35d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### now that we have stage 1 ensemble from 4 custom models, \n",
    "## we can do stage 2 ensemble using stage 1 output and stock YOLOv4 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06d286e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update weights for stage 1 output and stock yolo4:\n",
    "weights = [1, 1]    # here we assume the order is [Stage 1 ensemble, Stock YOLOv4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ab5255f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\168\\Anaconda3\\envs\\t4\\lib\\site-packages\\ensemble_boxes\\ensemble_boxes_wbf.py:85: UserWarning: Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.\n",
      "  warnings.warn('Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
      "C:\\Users\\168\\Anaconda3\\envs\\t4\\lib\\site-packages\\ensemble_boxes\\ensemble_boxes_wbf.py:73: UserWarning: X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.\n",
      "  warnings.warn('X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Run this cell to run Stage 2 ensemble and write results to txt files \"\"\"\n",
    "\n",
    "# generate a list of all images\n",
    "# since all models have predictions on the same test dataset, we can get this list from any 1 model\n",
    "all_img_preds = os.listdir(path_YOLO4)    # get list of file names without full path\n",
    "\n",
    "# gather paths for all 4 models\n",
    "model_paths = [stage1_output, path_stock_YOLO4]\n",
    "\n",
    "# work on 1 image at a time\n",
    "for img_pred in all_img_preds:\n",
    "    # instantiate master lists\n",
    "    boxes_master = []\n",
    "    scores_master = []\n",
    "    labels_master = []\n",
    "    # note: img_pred is something like 'A101.txt'\n",
    "    \n",
    "    # for this image, gather predictions from all 4 models, model by model\n",
    "    for model_path in model_paths:\n",
    "        # instantiate placeholders for this model\n",
    "        boxes_model = []\n",
    "        scores_model = []\n",
    "        labels_model = []\n",
    "        \n",
    "        # locate the prediction txt file\n",
    "        file = os.path.join(model_path, img_pred)\n",
    "        # read prediction file\n",
    "        with open(file, 'r') as f:\n",
    "            # read each line in prediction file\n",
    "            for line in f.readlines():\n",
    "                line = line.split()    # make line elements iterable\n",
    "                labels_model.append(int(line[0]))    # class id should be int\n",
    "                scores_model.append(float(line[1]))    # confidence score shoulbe be float\n",
    "                \n",
    "                # convert xywh to [x1, y1, x2, y2]\n",
    "                x, y, w, h = float(line[2]), float(line[3]), float(line[4]), float(line[5])\n",
    "                x1 = x - w/2\n",
    "                y1 = y - h/2\n",
    "                x2 = x + w/2\n",
    "                y2 = y + h/2\n",
    "                boxes_model.append([x1, y1, x2, y2])\n",
    "                \n",
    "        # now gather all 4 model predictions for this image \n",
    "        boxes_master.append(boxes_model)\n",
    "        scores_master.append(scores_model)\n",
    "        labels_master.append(labels_model)\n",
    "\n",
    "    # apply ensemble to all 4 model predictions for this image\n",
    "    boxes_ensemble, scores_ensemble, labels_ensemble = weighted_boxes_fusion(boxes_master, scores_master, labels_master, weights=weights, iou_thr=iou_thr, skip_box_thr=0.0)\n",
    "    \n",
    "#     # apply NMS to remove redundant boxes\n",
    "#     boxes_e_nms, scores_e_nms, labels_e_nms = nms_method([boxes_ensemble], [scores_ensemble], [labels_ensemble], method=3, weights=weights, iou_thr=iou_thr, sigma=0.5, thresh=0.001)\n",
    "\n",
    "    # apply confidence filter\n",
    "    boxes_e_c, scores_e_c, labels_e_c = predictions_above_confidence(boxes_ensemble, scores_ensemble, labels_ensemble, conf_thd)\n",
    "\n",
    "    # write ensemble results to txt file, we use the same file name as predictions, just store to different folder        \n",
    "    write_predictions_txt(boxes_e_c, scores_e_c, labels_e_c, stage2_output, img_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffd1704",
   "metadata": {},
   "source": [
    "#### visualize stage 2 ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "73cf7fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2058486321_8c8fbcbcd7_z\n",
      "6828176341_3a23aa4623_z\n",
      "8288873861_a24b6b421a_z\n",
      "8302503786_8820161815_z\n",
      "9663077996_31dd326967_z\n",
      "A858\n",
      "B193\n",
      "B365\n"
     ]
    }
   ],
   "source": [
    "# show some stock YOLOv4 predicitons on new tiny test dataset\n",
    "## new window will pop open, press any key to destroy and let new image pop up\n",
    "\n",
    "# loop thru all test images\n",
    "eight_imgs = os.listdir(s2_img_path)\n",
    "for img in eight_imgs:\n",
    "    file_name = img.split('.')[0]\n",
    "    print(file_name)\n",
    "    \n",
    "    # convert RODM format to EB format\n",
    "    boxes_list, scores_list, labels_list = load_pred(os.path.join(path_stock_YOLO4,file_name+'.txt'))\n",
    "\n",
    "    # visualize ensemble predictions for each image\n",
    "    show_boxes([boxes_list], [scores_list], [labels_list], os.path.join(s2_img_path,file_name+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "54d9cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2058486321_8c8fbcbcd7_z\n",
      "6828176341_3a23aa4623_z\n",
      "8288873861_a24b6b421a_z\n",
      "8302503786_8820161815_z\n",
      "9663077996_31dd326967_z\n",
      "A858\n",
      "B193\n",
      "B365\n"
     ]
    }
   ],
   "source": [
    "# show stage 2 ensemble on new tiny test dataset\n",
    "## new window will pop open, press any key to destroy and let new image pop up\n",
    "\n",
    "# loop thru all test images\n",
    "eight_imgs = os.listdir(s2_img_path)\n",
    "for img in eight_imgs:\n",
    "    file_name = img.split('.')[0]\n",
    "    print(file_name)\n",
    "    \n",
    "    # convert RODM format to EB format\n",
    "    boxes_list, scores_list, labels_list = load_pred(os.path.join(stage2_output,file_name+'.txt'))\n",
    "\n",
    "    # visualize ensemble predictions for each image\n",
    "    show_boxes([boxes_list], [scores_list], [labels_list], os.path.join(s2_img_path,file_name+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1444a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t4",
   "language": "python",
   "name": "t4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
